---
title: "miceFast - Introduction"
author: "Maciej Nasinski"
date: "`r Sys.Date()`"
output: 
  rmarkdown::pdf_document
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```


Loading packages and set.seed:

```{r,echo=TRUE}

library(miceFast)

set.seed(1234)
```

## Motivations

Missing data is a common problem. The easiest solution is to delete observations for which dependent variable is missing. But this will sometimes deteriorate quality of a project. Another solution will be to use methods such as multiple imputations to fill the missing data. Non missing independent variables could be used to approximate a missing observations for a dependent variable. R or Python language are comfortable for data manipulation but parallely brings slower computations. Languages such as C++ gives an opportunity to boost our applications or projects.

The presented miceFast package was built under Rcpp packages and the C++ library Armadillo.
The Rcpp package offers functionality of exporting full C++ capabilities to the R environment.
More precisely miceFast and corrData are offered. The first module offers capabilities of multiple imputations models with a closed-form solution. The main upgrade is possibility of including a grouping and/or weighting (only for linear models) variable and functions enhancement by C++ capabilities.

The second module was made for purpose of presenting the miceFast usage and performance. It provides functionality of generating correlated data with a discrete, binomial or continuous dependent variable and continuous independent variables. 

## Example

###Genereting Data by corrData Module

Available constructors:

**new(corrData,nr_cat,n_obs,means,cor_matrix)**

**new(corrData,n_obs,means,cor_matrix)**

where:

- nr_cat : number of categories for discrete dependent variable
- n_obs : number of observations
- means: center independent variables
- cor_mat : positive defined correlation matrix

relevant class methods:

- fill("type") : generating data

type - ("contin","binom","discrete")


Generating correlated data for all three possible data types of dependent variable

```{r,echo=TRUE}

power = 5 # power of 10 - number of observations - should be adjusted to a computer capabilities

grs = 10**(power-3) # grouping variable - number of groups

## generete example - data

##positive-defined correlation matrix

cors = matrix(c(1,0.6,0.7,0.4,0.4,0.5,0.35,
                NA,1,0.2,0.05,0.1,0.12,0.15,
                NA,NA,1,0.15,0.15,0.1,0.08,
                NA,NA,NA,1,0.12,0.15,0.1,
                NA,NA,NA,NA,1,0.15,0.2,
                NA,NA,NA,NA,NA,1,0.15,
                NA,NA,NA,NA,NA,NA,1),7,7,byrow = TRUE)

cors[lower.tri(cors)] = t(cors)[lower.tri(cors)]

n_vars = 7 # number of variables

# automatic corr matrix - close to diagonal

#cors = stats::rWishart(100,10,diag(7)) 

#cors = apply(cors,1:2,mean)/10

#cors

##

model = new(corrData,10,10^power,rep(0,7),cors)

data_bin = model$fill("binom")
data_disc = model$fill("discrete")
data_con = model$fill("contin")

n_vars = ncol(cors)

posit_y = 1
posit_x = 2:(n_vars-1)
posit_grs = n_vars
posit_indexNA = n_vars+1
```

Sampling 10% of observations - artificial missing values:

```{r,echo=TRUE,echo=TRUE}
## NA index
index_NA = 1:nrow(data_con) %in% sample(1:nrow(data_con),10^(power-1))

fill_NA = function(v,index_NA){

  v[index_NA] = NA

  v
}

```

A grouping variable:

```{r,echo=TRUE}
#Grouping variable

data_disc[,posit_grs] = floor(pnorm(data_disc[,posit_grs])*grs)

data_disc = data_disc[order(data_disc[,posit_grs]),] # sort by group

data_disc = cbind(data_disc,index_NA)

gr_disc = data_disc[,posit_grs]

index_NA = as.logical(data_disc[,posit_grs])# index_NA after sorting

#continous model

data_con[,posit_grs] = floor(pnorm(data_con[,posit_grs])*grs)

data_con = cbind(data_con,index_NA)

data_con = data_con[order(data_con[,posit_grs]),] # sort by group

gr_con = data_con[,posit_grs]

index_NA = as.logical(data_disc[,posit_indexNA])# index_NA after sorting
```

Presenting Data - Continuous & Discrete:

```{r,echo=TRUE}
# round(head(data_disc),3)
# round(head(data_con),3)
# 
# round(cor(data_disc),3)
# round(cor(data_con),3)
```

###Imputations

Building miceFast objects - a simple model or with a grouping variable:

available constructors:

**new(miceFast,x)**

**new(miceFast,x,grouping,sorted)**

**new(miceFast,x,weights)**

**new(miceFast,x,grouping,sorted,weights)**

where:

- x : variables - type matrix
- grouping : vector of integers for grouping variable - you could build it form several discrete variables
- sorted : boolean (TRUE/FALSE) specifying if data is already sorted by a grouping variable
- weights: vector of weights for weighted linear regressions

relevant class methods:

- impute("model",posit_y,posit_x,force) - impute data under characterstics form object like a optional grouping or weighting variable
- get_models() - possible quantitative models for a certain type of dependent variable
- get_model() - a recommended quantitative model for a certain type of dependent variable
- get_index_NA_R(posit_y,posit_x) - index of rows where the data was imputed
- get_index_full_R(posit_y,posit_x) - index of rows which was used for model estimation
- is_VarsUpdated() - is variables at the object modified by impute with a force parameter set to TRUE

model - character - posibble options ("lda","lm_pred","lm_bayes","lm_noise")
model2 - character - posibble options ("lm_pred","lm_bayes","lm_noise")
posit_y - integer - position of dependent variable
posit_x - integer vector - positions of independent variables
force - boolen - if you want to update variables at object for next imputations use TRUE

- for simple mean use "lm_pred" and x=as.matrix(rep(1,"nrow"))

Base model:

Continuous data:

```{r,echo=TRUE}

model = new(miceFast,cbind(fill_NA(data_con[,posit_y],index_NA),data_con[,posit_x]))

#get availible predction models
model$get_models(posit_y)

#get recommended prediction model

model$get_model(posit_y)

#implementing lm_pred
pred =  model$impute("lm_pred",posit_y,posit_x,FALSE)

sum((pred$imputations[pred$index_NA]-data_con[index_NA,1])^2)

```

Discrete data:

```{r,echo=TRUE}

model = new(miceFast,cbind(fill_NA(data_disc[,posit_y],index_NA),data_disc[,posit_x]))

#get availible predction models for variable 1

model$get_models(posit_y)

#implementing lda
pred =  model$impute("lda",posit_y,posit_x,FALSE)

index_imp = model$get_index_NA_R(posit_y,posit_x)

table(pred$imputations[pred$index_NA],data_disc[index_NA,1])

```

Using a grouping variable:

Continuous data:

```{r,echo=TRUE}

model = new(miceFast,cbind(fill_NA(data_con[,posit_y],index_NA),data_con[,posit_x]),gr_con,FALSE)

#get availible predction models for variable 1

model$get_models(posit_y)

#implementing lm_pred
pred =  model$impute("lm_pred",posit_y,posit_x,FALSE)

index_imp = model$get_index_NA_R(posit_y,posit_x)

sum((pred$imputations[pred$index_NA]-data_con[index_NA,1])^2)

head(cbind(pred$imputations[pred$index_NA],data_con[index_NA,1]))

```

Discrete data:

```{r,echo=TRUE}

model = new(miceFast,x=cbind(fill_NA(data_disc[,posit_y],index_NA),data_disc[,posit_x]),gr_disc,TRUE)

#get availible predction models for variable 1

model$get_models(posit_y)

#implementing lda
pred =  model$impute("lda",posit_y,posit_x,FALSE)

table(pred$imputations[pred$index_NA],data_disc[index_NA,1])

```

###Additional functionality -  weighted linear regressions

Weights:

```{r,echo=T}
weights = pnorm(data_con[,6])
```

Base model:

```{r,echo=TRUE}

model = new(miceFast,cbind(fill_NA(data_con[,posit_y],index_NA),data_con[,posit_x[-length(posit_x)]]),weights)

#get availible predction models

model$get_models(posit_y)

#implementing lm_pred
pred =  model$impute("lm_pred",posit_y,posit_x[-length(posit_x)],FALSE)

index_imp =  model$get_index_NA_R(posit_y,posit_x[-length(posit_x)])

sum((pred$imputations[pred$index_NA]-data_con[index_NA,1])^2)

head(cbind(pred$imputations[pred$index_NA],data_con[index_NA,1]))

rm(model)

```

with grouping variable:

```{r,echo=TRUE}

model = new(miceFast,cbind(fill_NA(data_con[,posit_y],index_NA),data_con[,posit_x[-length(posit_x)]]),data_con[,posit_grs],TRUE,weights)

#get availible predction models
model$get_models(posit_y)

#implementing lm_pred
pred =  model$impute("lm_pred",posit_y,posit_x[-length(posit_x)],FALSE)

index_imp =  model$get_index_NA_R(posit_y,posit_x[-length(posit_x)])

sum((pred$imputations[pred$index_NA]-data_con[index_NA,1])^2)

head(cbind(pred$imputations[pred$index_NA],data_con[index_NA,1]))

```

##Performance

Environment: MRO Intel MKL - i7 6700HQ and 24GB DDR4 2133

MRO (Microsoft R Open) provide to R a sophisticated library for linear algebra operations so remember about that when reading a performance comparision. For example at MRO a X'X operation is a few hundred times faster than at regular R.

If you are interested about the procedure of testing performance check performance_validity.R file at extdata folder.

```{r,eval=FALSE,echo=TRUE}
system.file("extdata","performance_validity.R",package = "miceFast")
```

Additinal plots for simulations with certain parmaeters (but feel free to change them) are located:

```{r,eval=FALSE,echo=TRUE}
system.file("extdata","images",package = "miceFast")
```


Mice fast was compared with the mice package. For grouping option there was used a basic R looping and the popular dplyr package.

Summing up, miceFast offer a relevant boost of calculations for LDA and all implemented models with grouping option. 
